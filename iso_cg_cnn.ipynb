{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iso_cg_cnn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXtbiyK97RYGlWmR1/9Pxa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yifan-zhou19/iso/blob/master/iso_cg_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klaFMK9DDZ7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5e5cb11e-03fb-41d9-854e-38fc7606962a"
      },
      "source": [
        "##################\n",
        "# DATA IMPORTING #\n",
        "##################\n",
        "\n",
        "from os.path import exists\n",
        "\n",
        "!wget -O cwe119_cgd.txt https://raw.githubusercontent.com/CGCL-codes/VulDeePecker/master/CWE-119/CGD/cwe119_cgd.txt\n",
        "\n",
        "print()\n",
        "\n",
        "with open(\"./cwe119_cgd.txt\", \"r\") as cgd:\n",
        "  print(\"Source: \",cgd.readline())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-13 19:49:31--  https://raw.githubusercontent.com/CGCL-codes/VulDeePecker/master/CWE-119/CGD/cwe119_cgd.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17202057 (16M) [text/plain]\n",
            "Saving to: ‘cwe119_cgd.txt’\n",
            "\n",
            "cwe119_cgd.txt      100%[===================>]  16.40M  27.1MB/s    in 0.6s    \n",
            "\n",
            "2020-04-13 19:49:33 (27.1 MB/s) - ‘cwe119_cgd.txt’ saved [17202057/17202057]\n",
            "\n",
            "\n",
            "Source:  1 CVE-2010-1444/vlc_media_player_1.1.0_CVE-2010-1444_zipstream.c cfunc 449\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JOGIR2lDh4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ff71beb8-1a78-4792-9e20-cf954a37b343"
      },
      "source": [
        "import re\n",
        "re_punctuation_string = '[()\\s,/.\\']'\n",
        "programs=[]\n",
        "program = []\n",
        "statement=[]\n",
        "labels = []\n",
        "vocabulary = [] \n",
        "remove_token=['',' ',',','NULL','\\n',';']\n",
        "with open(\"./cwe119_cgd.txt\", \"r\") as cgd:\n",
        "  lines = cgd.readlines()\n",
        "  for line in lines:\n",
        "    statement=[token for token in re.split(re_punctuation_string,line)if token not in remove_token]\n",
        "    #print(statement)\n",
        "    if statement == ['---------------------------------']:\n",
        "      if program[-1] == ['0']:\n",
        "        labels.append(0)\n",
        "      elif program[-1] == ['1']:\n",
        "        labels.append(1)\n",
        "      programs.append(program[1:-2])\n",
        "      for s in program[1:]:\n",
        "        for t in s:\n",
        "           if t not in vocabulary:\n",
        "             vocabulary.append(t)\n",
        "      #print(program)\n",
        "      program = []\n",
        "    else:\n",
        "      program.append(statement)\n",
        "\n",
        "print(len(labels))\n",
        "\n",
        "\n",
        "  \n",
        "print(len(vocabulary))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39753\n",
            "22631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq1TtXI_DnY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shuffle data\n",
        "import random\n",
        "randnum = random.randint(0,100)\n",
        "random.seed(randnum)\n",
        "random.shuffle(programs)\n",
        "random.seed(randnum)\n",
        "random.shuffle(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaA-A4unDotp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "1ff24568-0995-465b-bc8e-f950c9b94f4a"
      },
      "source": [
        "training_data = []\n",
        "for i in range(10000):\n",
        "  training_data.append((programs[i],labels[i]))\n",
        "print(training_data[:2])\n",
        "\n",
        "eval_data=[]\n",
        "for i in range(10000,15000):\n",
        "  eval_data.append((programs[i],labels[i]))\n",
        "print(eval_data[:2])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[([['void', 'CWE122_Heap_Based_Buffer_Overflow__c_CWE806_char_ncpy_52b_goodG2BSink', 'char', '*', 'data'], ['CWE122_Heap_Based_Buffer_Overflow__c_CWE806_char_ncpy_52c_goodG2BSink', 'data'], ['void', 'CWE122_Heap_Based_Buffer_Overflow__c_CWE806_char_ncpy_52c_goodG2BSink', 'char', '*', 'data'], ['strncpy', 'dest', 'data', 'strlen', 'data'], ['printLine', 'data']], 0), ([['recvResult', '=', 'recv', 'connectSocket', 'inputBuffer', 'CHAR_ARRAY_SIZE', '-', '1', '0'], ['if', 'recvResult', '==', 'SOCKET_ERROR', '||', 'recvResult', '==', '0'], ['inputBuffer[recvResult]', '=', '\\\\0'], ['data', '=', 'atoi', 'inputBuffer'], ['if', 'data', '>=', '0']], 1)]\n",
            "[([['void', 'badSource', 'wchar_t', '*', '&data'], ['wchar_t', '*', 'dataBuffer', '=', 'wchar_t', '*', 'ALLOCA', '100*sizeof', 'wchar_t'], ['data', '=', 'dataBuffer;'], ['badSource', 'data'], ['wchar_t', 'dest[50]', '=', 'L\"\";']], 1), ([['data', '=', 'NULL;'], ['data[0]', '=', 'L', '\\\\0'], ['wcscpy', 'data', 'source'], ['printWLine', 'data']], 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJbgCeuEDxKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c49a3ef-01b8-4265-8f0a-987389ba9d2e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "#look up table  \n",
        "#using one-hot embedding\n",
        "vocabulary_size = len(vocabulary)\n",
        "def look_up_table(word_idx):\n",
        "  x = torch.zeros(vocabulary_size).long()\n",
        "  x[word_idx] = 1.0\n",
        "  return x\n",
        "word2idx = {w: idx +1 for (idx, w) in enumerate(vocabulary)}\n",
        "idx2word = {idx+1: w for (idx, w) in enumerate(vocabulary)}\n",
        "print(look_up_table(word2idx['1']))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0,  ..., 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzeY5VO0Dz0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "8ea2f1d3-01c9-45b8-a008-f0e0b78738f6"
      },
      "source": [
        "context_size = 20\n",
        "def get_programcontext(program):\n",
        "  id = 0\n",
        "  contexts =torch.zeros(context_size,1).long()\n",
        "  for p in program:\n",
        "    for t in p:\n",
        "      if id < context_size:\n",
        "        contexts[id]= word2idx[t]\n",
        "        id = id +1\n",
        "      else:\n",
        "        return contexts\n",
        "  return contexts\n",
        "get_programcontext(programs[4920])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4078],\n",
              "        [   5],\n",
              "        [ 743],\n",
              "        [4079],\n",
              "        [4080],\n",
              "        [   5],\n",
              "        [ 168],\n",
              "        [4078],\n",
              "        [  99],\n",
              "        [ 168],\n",
              "        [4081],\n",
              "        [  99],\n",
              "        [ 539],\n",
              "        [4082],\n",
              "        [   5],\n",
              "        [ 127],\n",
              "        [ 638],\n",
              "        [4080],\n",
              "        [ 352],\n",
              "        [ 151]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HomFRi9cD36i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "a6fb9032-fe00-440f-c365-3a460c0e91ab"
      },
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "embedding_dim =15\n",
        "class ProgrammingML(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(ProgrammingML, self).__init__()\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.conv1 = nn.Conv1d(1, 9, (5,embedding_dim),padding =(2,0))\n",
        "    self.conv2 = nn.Conv2d(9, 5, (2,1))\n",
        "    self.fc1 = nn.Linear(5*19, 2)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    #print(inputs.size())\n",
        "    embeds = self.embeddings(inputs.view(-1))\n",
        "    #print(embeds.size())\n",
        "    out = self.conv1(embeds.view(1,1,context_size,embedding_dim))\n",
        "    #print(out.size())\n",
        "    out = self.conv2(out)\n",
        "    #print(out.size())\n",
        "    out = F.softmax(self.fc1(out.view(-1)),dim=0)\n",
        "    return out\n",
        "\n",
        "\n",
        "losses = []\n",
        "loss_function = nn.BCELoss()\n",
        "model = ProgrammingML(vocabulary_size, embedding_dim)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(20):\n",
        "  losses = 0\n",
        "  for program, label in training_data:\n",
        "   # print(program)\n",
        "   # print(label)\n",
        "   if label ==1:\n",
        "     out_labels = torch.FloatTensor([0,1])\n",
        "   else:\n",
        "     out_labels  = torch.FloatTensor([1,0])\n",
        "\n",
        "   context_idx = get_programcontext(program)\n",
        "   model.zero_grad()\n",
        "   out = model(context_idx)\n",
        "   #print(out.size())\n",
        "   #print(f'Out {out}')\n",
        "   #print(out_labels)\n",
        "   loss = loss_function(out, out_labels )\n",
        "   #print(f'Loss {loss.item()}')\n",
        "   loss.backward()\n",
        "   optimizer.step()\n",
        "   #print(f'Loss {loss.item()}')\n",
        "   losses +=loss.item()\n",
        "  print(f'Loss at epo {epoch}: {losses/len(training_data)}')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epo 0: 0.44414275987961155\n",
            "Loss at epo 1: 0.32658981557295114\n",
            "Loss at epo 2: 0.28461441633015255\n",
            "Loss at epo 3: 0.2626896175176947\n",
            "Loss at epo 4: 0.2482062248843443\n",
            "Loss at epo 5: 0.23725426327071156\n",
            "Loss at epo 6: 0.22817165221168015\n",
            "Loss at epo 7: 0.22065010371772859\n",
            "Loss at epo 8: 0.21416260230483358\n",
            "Loss at epo 9: 0.2081609038558893\n",
            "Loss at epo 10: 0.2025424870689728\n",
            "Loss at epo 11: 0.19763052361450603\n",
            "Loss at epo 12: 0.1933149495722091\n",
            "Loss at epo 13: 0.189573594894691\n",
            "Loss at epo 14: 0.18661215077272103\n",
            "Loss at epo 15: 0.18396923899878423\n",
            "Loss at epo 16: 0.181193152381992\n",
            "Loss at epo 17: 0.1786337698992101\n",
            "Loss at epo 18: 0.17636177691284735\n",
            "Loss at epo 19: 0.17371436395053277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCtIAX0qD6z2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "410835e3-d21a-479a-8de5-bd8f5314ec57"
      },
      "source": [
        "with torch.no_grad():\n",
        "  accurate = 0\n",
        "  for program, label in eval_data:\n",
        "   # print(program)\n",
        "   # print(label)\n",
        "   context_idx = get_programcontext(program)\n",
        "   model.zero_grad()\n",
        "   out = model(context_idx)\n",
        "   #print(f'{out}:{label}')\n",
        "   if(out[0]>0.5):\n",
        "     if(label == 0):\n",
        "       accurate =accurate+1\n",
        "   elif(out[1]>0.5):\n",
        "     if(label == 1):\n",
        "       accurate = accurate+1\n",
        "  print(f'Accuracy: {accurate/len(eval_data)}')   "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eALWXTJTWCI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cf427abc-7d2e-4c55-8bda-c7bf566437e3"
      },
      "source": [
        "with torch.no_grad():\n",
        "  accurate = 0\n",
        "  for program, label in eval_data:\n",
        "   # print(program)\n",
        "   # print(label)\n",
        "   context_idx = get_programcontext(program)\n",
        "   model.zero_grad()\n",
        "   out = model(context_idx)\n",
        "   #print(f'{out}:{label}')\n",
        "   if(out[0]>0.5):\n",
        "     if(label == 0):\n",
        "       accurate =accurate+1\n",
        "   elif(out[1]>0.5):\n",
        "     if(label == 1):\n",
        "       accurate = accurate+1\n",
        "  print(f'Accuracy: {accurate/len(eval_data)}')  "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8676\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}