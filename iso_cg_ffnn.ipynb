{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iso_cg_ffnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2P3QMOEIjA8",
        "colab_type": "code",
        "outputId": "f06cb875-1838-4d33-81d0-02da23e860e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "##################\n",
        "# DATA IMPORTING #\n",
        "##################\n",
        "\n",
        "from os.path import exists\n",
        "\n",
        "!wget -O cwe119_cgd.txt https://raw.githubusercontent.com/CGCL-codes/VulDeePecker/master/CWE-119/CGD/cwe119_cgd.txt\n",
        "\n",
        "print()\n",
        "\n",
        "with open(\"./cwe119_cgd.txt\", \"r\") as cgd:\n",
        "  print(\"Source: \",cgd.readline())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-13 11:00:21--  https://raw.githubusercontent.com/CGCL-codes/VulDeePecker/master/CWE-119/CGD/cwe119_cgd.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17202057 (16M) [text/plain]\n",
            "Saving to: ‘cwe119_cgd.txt’\n",
            "\n",
            "cwe119_cgd.txt      100%[===================>]  16.40M  32.0MB/s    in 0.5s    \n",
            "\n",
            "2020-04-13 11:00:21 (32.0 MB/s) - ‘cwe119_cgd.txt’ saved [17202057/17202057]\n",
            "\n",
            "\n",
            "Source:  1 CVE-2010-1444/vlc_media_player_1.1.0_CVE-2010-1444_zipstream.c cfunc 449\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fBY-ym7MqoH",
        "colab_type": "code",
        "outputId": "a23abf88-3e4b-4045-e8bb-6ad9ad2bb632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import re\n",
        "re_punctuation_string = '[()\\s,/.\\']'\n",
        "programs=[]\n",
        "program = []\n",
        "statement=[]\n",
        "labels = []\n",
        "vocabulary = [] \n",
        "remove_token=['',' ',',','NULL','\\n',';']\n",
        "with open(\"./cwe119_cgd.txt\", \"r\") as cgd:\n",
        "  lines = cgd.readlines()\n",
        "  for line in lines:\n",
        "    statement=[token for token in re.split(re_punctuation_string,line)if token not in remove_token]\n",
        "    #print(statement)\n",
        "    if statement == ['---------------------------------']:\n",
        "      if program[-1] == ['0']:\n",
        "        labels.append(0)\n",
        "      elif program[-1] == ['1']:\n",
        "        labels.append(1)\n",
        "      programs.append(program[1:-2])\n",
        "      for s in program[1:]:\n",
        "        for t in s:\n",
        "           if t not in vocabulary:\n",
        "             vocabulary.append(t)\n",
        "      #print(program)\n",
        "      program = []\n",
        "    else:\n",
        "      program.append(statement)\n",
        "\n",
        "print(len(labels))\n",
        "\n",
        "\n",
        "  \n",
        "print(len(vocabulary))\n",
        "   "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39753\n",
            "22631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hoxbji00476j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shuffle data\n",
        "import random\n",
        "randnum = random.randint(0,100)\n",
        "random.seed(randnum)\n",
        "random.shuffle(programs)\n",
        "random.seed(randnum)\n",
        "random.shuffle(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFj_HuQc1k3A",
        "colab_type": "code",
        "outputId": "941afa04-a636-4008-b67d-c4da2fa3cd18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#print(vocabulary[:20])\n",
        "print(len([one for one in labels[:10000] if one == 1 ]))\n",
        "print(len([zero for zero in labels[:10000] if zero == 0 ]))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2591\n",
            "7409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RRoEHvz3RFz",
        "colab_type": "code",
        "outputId": "a11bb4e4-6246-44fe-fcd0-4284bf3eb689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(len([one for one in labels[10000:15000] if one == 1 ]))\n",
        "print(len([zero for zero in labels[10000:15000] if zero == 0]))\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1292\n",
            "3708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDhsxT2HATaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "051a1377-61a7-4cf5-9395-3d06b23dd968"
      },
      "source": [
        "training_data = []\n",
        "for i in range(10000):\n",
        "  training_data.append((programs[i],labels[i]))\n",
        "print(training_data[:2])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[([['ss_tc_root', '=', 'getenv', '\"SS_TC_ROOT\"'], ['size_dirpath', '=', 'strlen', 'ss_tc_root', '+', 'strlen', '\"testData\"', '+', '2;'], ['dirpath', '=', 'char*', 'malloc', 'size_dirpath', '*', 'sizeof', 'char'], ['sprintf', 'dirpath', '\"%s', '%s\"', 'ss_tc_root', '\"testData\"'], ['if', 'stat', 'dirpath', '&st', '==', '-1', '{'], ['retval', '=', 'mkdir', 'dirpath', '0700'], ['size_filepath', '=', 'strlen', 'dirpath', '+', 'strlen', '\"logfile', 'txt\"', '+', '2;']], 0), ([['data', '=', 'NULL;'], ['goodG2BSource', 'data'], ['void', 'goodG2BSource', 'wchar_t', '*', '&data'], ['data', '=', 'new', 'wchar_t[100];'], ['data[0]', '=', 'L', '\\\\0'], ['goodG2BSource', 'data'], ['wchar_t', 'source[100];'], ['wmemset', 'source', 'L', 'C', '100-1'], ['source[100-1]', '=', 'L', '\\\\0']], 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGMHg4rLvs38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7c05ff15-b7f5-4cbe-ccf1-07a5e7ef2ceb"
      },
      "source": [
        "eval_data=[]\n",
        "for i in range(10000,15000):\n",
        "  eval_data.append((programs[i],labels[i]))\n",
        "print(eval_data[:2])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[([['data', '=', 'new', 'char[10];'], ['char', 'source[10+1]', '=', 'SRC_STRING;']], 1), ([['data', '=', 'new', 'wchar_t[10];'], ['wchar_t', '*', 'data', '=', 'CWE122_Heap_Based_Buffer_Overflow__cpp_CWE193_wchar_t_cpy_68_badData;'], ['wchar_t', 'source[10+1]', '=', 'SRC_STRING;']], 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rx9mY-Q3isJ",
        "colab_type": "code",
        "outputId": "d86dd904-12bd-416d-f7ad-f249ad85d192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "#look up table  \n",
        "#using one-hot embedding\n",
        "vocabulary_size = len(vocabulary)\n",
        "def look_up_table(word_idx):\n",
        "  x = torch.zeros(vocabulary_size).long()\n",
        "  x[word_idx] = 1.0\n",
        "  return x\n",
        "word2idx = {w: idx +1 for (idx, w) in enumerate(vocabulary)}\n",
        "idx2word = {idx+1: w for (idx, w) in enumerate(vocabulary)}\n",
        "print(look_up_table(word2idx['1']))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0,  ..., 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvyUKYKSHPlR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "8a16fead-5b56-41a1-a50a-f78d012bcf93"
      },
      "source": [
        "context_size = 20\n",
        "def get_programcontext(program):\n",
        "  id = 0\n",
        "  contexts =torch.zeros(context_size,1).long()\n",
        "  for p in program:\n",
        "    for t in p:\n",
        "      if id < context_size:\n",
        "        contexts[id]= word2idx[t]\n",
        "        id = id +1\n",
        "      else:\n",
        "        return contexts\n",
        "  return contexts\n",
        "get_programcontext(programs[4920])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  615],\n",
              "        [  352],\n",
              "        [  855],\n",
              "        [  315],\n",
              "        [    5],\n",
              "        [  285],\n",
              "        [  315],\n",
              "        [    5],\n",
              "        [ 3009],\n",
              "        [13699],\n",
              "        [  615],\n",
              "        [13535],\n",
              "        [    5],\n",
              "        [  669],\n",
              "        [    0],\n",
              "        [    0],\n",
              "        [    0],\n",
              "        [    0],\n",
              "        [    0],\n",
              "        [    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICfbHSXT5BLH",
        "colab_type": "code",
        "outputId": "8abede0a-8da3-4ca0-a0a5-55c2b65fef16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "embedding_dim =15\n",
        "class ProgrammingML(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(ProgrammingML, self).__init__()\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.conv1 = nn.Conv2d(1, 3, 2)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 2)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 2)\n",
        "\n",
        "    self.linear1 = nn.Linear(embedding_dim*context_size,10)\n",
        "    self.linear2 = nn.Linear(10,2)\n",
        "  def forward(self, inputs):\n",
        "    #print(inputs.size())\n",
        "    embeds = self.embeddings(inputs.view(-1))\n",
        "    #print(embeds)\n",
        "    out = F.relu(self.linear1(embeds.view(-1)))\n",
        "    out = F.softmax(self.linear2(out),dim=0)\n",
        "    return out\n",
        "\n",
        "\n",
        "losses = []\n",
        "loss_function = nn.BCELoss()\n",
        "model = ProgrammingML(vocabulary_size, embedding_dim)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(20):\n",
        "  losses = 0\n",
        "  for program, label in training_data:\n",
        "   # print(program)\n",
        "   # print(label)\n",
        "   if label ==1:\n",
        "     out_labels = torch.FloatTensor([0,1])\n",
        "   else:\n",
        "     out_labels  = torch.FloatTensor([1,0])\n",
        "\n",
        "   context_idx = get_programcontext(program)\n",
        "   model.zero_grad()\n",
        "   out = model(context_idx)\n",
        "   #print(out.size())\n",
        "   #print(f'Out {out}')\n",
        "   #print(out_labels)\n",
        "   loss = loss_function(out, out_labels )\n",
        "   #print(f'Loss {loss.item()}')\n",
        "   loss.backward()\n",
        "   optimizer.step()\n",
        "   #print(f'Loss {loss.item()}')\n",
        "   losses +=loss.item()\n",
        "  print(f'Loss at epo {epoch}: {losses/len(training_data)}')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epo 0: 0.4403967569380693\n",
            "Loss at epo 1: 0.33170990852703663\n",
            "Loss at epo 2: 0.2784942467651442\n",
            "Loss at epo 3: 0.2468668150356145\n",
            "Loss at epo 4: 0.2260661949796362\n",
            "Loss at epo 5: 0.2098709678972226\n",
            "Loss at epo 6: 0.19885025114645813\n",
            "Loss at epo 7: 0.1898927681236528\n",
            "Loss at epo 8: 0.18199425340939737\n",
            "Loss at epo 9: 0.17669907976739063\n",
            "Loss at epo 10: 0.17117849828815696\n",
            "Loss at epo 11: 0.16730360337942435\n",
            "Loss at epo 12: 0.16468833964268786\n",
            "Loss at epo 13: 0.16211086302018698\n",
            "Loss at epo 14: 0.1595430445607416\n",
            "Loss at epo 15: 0.15744020290338673\n",
            "Loss at epo 16: 0.1556066154135405\n",
            "Loss at epo 17: 0.15400628118536444\n",
            "Loss at epo 18: 0.15191232715043063\n",
            "Loss at epo 19: 0.15065191360464777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Q58gRPvdOP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "49fb8b58-8fa2-4d88-ac2c-6e4dad31d5b7"
      },
      "source": [
        "with torch.no_grad():\n",
        "  accurate = 0\n",
        "  for program, label in eval_data:\n",
        "   # print(program)\n",
        "   # print(label)\n",
        "   context_idx = get_programcontext(program)\n",
        "   model.zero_grad()\n",
        "   out = model(context_idx)\n",
        "   #print(f'{out}:{label}')\n",
        "   if(out[0]>0.5):\n",
        "     if(label == 0):\n",
        "       accurate =accurate+1\n",
        "   elif(out[1]>0.5):\n",
        "     if(label == 1):\n",
        "       accurate = accurate+1\n",
        "  print(f'Accuracy: {accurate/len(eval_data)}')   "
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-JNCmWy4iO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}