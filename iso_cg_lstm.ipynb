{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iso_cg_lstm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOjZDnQilR/Ri+Vc1oj17/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yifan-zhou19/iso/blob/master/iso_cg_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnKGF-jDOfX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "9cf0784f-6be1-4f05-f29c-4428277498c8"
      },
      "source": [
        "##################\n",
        "# DATA IMPORTING #\n",
        "##################\n",
        "\n",
        "from os.path import exists\n",
        "\n",
        "!wget -O cwe119_cgd.txt https://raw.githubusercontent.com/CGCL-codes/VulDeePecker/master/CWE-119/CGD/cwe119_cgd.txt\n",
        "\n",
        "print()\n",
        "\n",
        "with open(\"./cwe119_cgd.txt\", \"r\") as cgd:\n",
        "  print(\"Source: \",cgd.readline())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-15 09:45:23--  https://raw.githubusercontent.com/CGCL-codes/VulDeePecker/master/CWE-119/CGD/cwe119_cgd.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17202057 (16M) [text/plain]\n",
            "Saving to: ‘cwe119_cgd.txt’\n",
            "\n",
            "cwe119_cgd.txt      100%[===================>]  16.40M  26.3MB/s    in 0.6s    \n",
            "\n",
            "2020-04-15 09:45:24 (26.3 MB/s) - ‘cwe119_cgd.txt’ saved [17202057/17202057]\n",
            "\n",
            "\n",
            "Source:  1 CVE-2010-1444/vlc_media_player_1.1.0_CVE-2010-1444_zipstream.c cfunc 449\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngvF--HjOqO4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4ed70912-06cf-4c9f-ef09-e46fff256797"
      },
      "source": [
        "import re\n",
        "re_punctuation_string = '[()\\s,/.\\']'\n",
        "programs=[]\n",
        "program = []\n",
        "statement=[]\n",
        "labels = []\n",
        "vocabulary = [] \n",
        "remove_token=['',' ',',','NULL','\\n',';']\n",
        "with open(\"./cwe119_cgd.txt\", \"r\") as cgd:\n",
        "  lines = cgd.readlines()\n",
        "  for line in lines:\n",
        "    statement=[token for token in re.split(re_punctuation_string,line)if token not in remove_token]\n",
        "    #print(statement)\n",
        "    if statement == ['---------------------------------']:\n",
        "      if program[-1] == ['0']:\n",
        "        labels.append(0)\n",
        "      elif program[-1] == ['1']:\n",
        "        labels.append(1)\n",
        "      programs.append(program[1:-2])\n",
        "      for s in program[1:]:\n",
        "        for t in s:\n",
        "           if t not in vocabulary:\n",
        "             vocabulary.append(t)\n",
        "      #print(program)\n",
        "      program = []\n",
        "    else:\n",
        "      program.append(statement)\n",
        "\n",
        "print(len(labels))\n",
        "\n",
        "\n",
        "  \n",
        "print(len(vocabulary))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39753\n",
            "22631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0MJ1w0rOq-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shuffle data\n",
        "import random\n",
        "randnum = random.randint(0,100)\n",
        "random.seed(randnum)\n",
        "random.shuffle(programs)\n",
        "random.seed(randnum)\n",
        "random.shuffle(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFe18QauOtf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "df465180-aaa2-4f5e-d3f9-ea590801acf5"
      },
      "source": [
        "training_data = []\n",
        "for i in range(10000):\n",
        "  training_data.append((programs[i],labels[i]))\n",
        "print(training_data[:2])\n",
        "\n",
        "eval_data=[]\n",
        "for i in range(10000,15000):\n",
        "  eval_data.append((programs[i],labels[i]))\n",
        "print(eval_data[:2])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[([['data', '=', 'NULL;'], ['data', '=', 'new', 'wchar_t[100];'], ['data[0]', '=', 'L', '\\\\0'], ['wchar_t', '*', 'dataCopy', '=', 'data;'], ['wchar_t', '*', 'data', '=', 'dataCopy;'], ['wchar_t', 'source[100];'], ['wmemset', 'source', 'L', 'C', '100-1'], ['source[100-1]', '=', 'L', '\\\\0']], 0), ([['data', '=', 'NULL;'], ['if', 'globalTrue'], ['char', '*', 'dataBuffer', '=', 'new', 'char[100];'], ['memset', 'dataBuffer', 'A', '100-1'], ['dataBuffer[100-1]', '=', '\\\\0'], ['data', '=', 'dataBuffer', '-', '8;'], ['char', 'source[100];'], ['memset', 'source', 'C', '100-1'], ['source[100-1]', '=', '\\\\0']], 1)]\n",
            "[([['c', '=', 'split', 'arg[i]', '\"=\"', '&n']], 0), ([['char', 'source[100];']], 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70hCv44MOw1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "222a5dc7-d40a-44da-9226-f3d4f6826d77"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "#look up table  \n",
        "#using one-hot embedding\n",
        "vocabulary_size = len(vocabulary)\n",
        "def look_up_table(word_idx):\n",
        "  x = torch.zeros(vocabulary_size).long()\n",
        "  x[word_idx] = 1.0\n",
        "  return x\n",
        "word2idx = {w: idx +1 for (idx, w) in enumerate(vocabulary)}\n",
        "idx2word = {idx+1: w for (idx, w) in enumerate(vocabulary)}\n",
        "print(look_up_table(word2idx['1']))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0,  ..., 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8bfkaVuO0Ek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "10b8bcca-80b8-44f7-e174-8f12b0504f71"
      },
      "source": [
        "context_size = 20\n",
        "def get_programcontext(program):\n",
        "  id = 0\n",
        "  contexts =torch.zeros(context_size,1).long()\n",
        "  for p in program:\n",
        "    for t in p:\n",
        "      if id < context_size:\n",
        "        contexts[id]= word2idx[t]\n",
        "        id = id +1\n",
        "      else:\n",
        "        return contexts\n",
        "  return contexts\n",
        "get_programcontext(programs[4920])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   63],\n",
              "        [13942],\n",
              "        [13943],\n",
              "        [13944],\n",
              "        [    3],\n",
              "        [ 1923],\n",
              "        [    5],\n",
              "        [  285],\n",
              "        [    8],\n",
              "        [ 1015],\n",
              "        [    5],\n",
              "        [  364],\n",
              "        [11266],\n",
              "        [  794],\n",
              "        [  470],\n",
              "        [13924],\n",
              "        [  108],\n",
              "        [    8],\n",
              "        [13945],\n",
              "        [    5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0grpIvVoO2qM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "44937a4c-e756-40e1-cc9a-c1809a5150b5"
      },
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "embedding_dim =15\n",
        "hidden_dim=15\n",
        "class ProgrammingML(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(ProgrammingML, self).__init__()\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "    self.fc1 = nn.Linear(hidden_dim, 2)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    #print(inputs.size())\n",
        "    embeds = self.embeddings(inputs)\n",
        "    #print(embeds.size())\n",
        "    lstm_out, _ = self.lstm(embeds.view(len(inputs), 1, -1))\n",
        "    #print(out.size())\n",
        "    out =  self.fc1(lstm_out.view(len(inputs), -1))\n",
        "    #print(out.size())\n",
        "    out = F.softmax(out,dim=1)\n",
        "    return out[-1]\n",
        "\n",
        "\n",
        "losses = []\n",
        "loss_function = nn.BCELoss()\n",
        "model = ProgrammingML(vocabulary_size, embedding_dim)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(20):\n",
        "  losses = 0\n",
        "  for program, label in training_data:\n",
        "   # print(program)\n",
        "   # print(label)\n",
        "   if label ==1:\n",
        "     out_labels = torch.FloatTensor([0,1])\n",
        "   else:\n",
        "     out_labels  = torch.FloatTensor([1,0])\n",
        "\n",
        "   context_idx = get_programcontext(program)\n",
        "   model.zero_grad()\n",
        "   out = model(context_idx)\n",
        "   #print(out.size())\n",
        "   #print(f'Out {out}')\n",
        "   #print(out_labels)\n",
        "   loss = loss_function(out, out_labels )\n",
        "   #print(f'Loss {loss.item()}')\n",
        "   loss.backward()\n",
        "   optimizer.step()\n",
        "   #print(f'Loss {loss.item()}')\n",
        "   losses +=loss.item()\n",
        "  print(f'Loss at epo {epoch}: {losses/len(training_data)}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epo 0: 0.42527033230392264\n",
            "Loss at epo 1: 0.2945441125874175\n",
            "Loss at epo 2: 0.2568398194457404\n",
            "Loss at epo 3: 0.23589682400966994\n",
            "Loss at epo 4: 0.2215443691034423\n",
            "Loss at epo 5: 0.20977593923241292\n",
            "Loss at epo 6: 0.20020808966690384\n",
            "Loss at epo 7: 0.19178073123257708\n",
            "Loss at epo 8: 0.18497784415003662\n",
            "Loss at epo 9: 0.17921896629857073\n",
            "Loss at epo 10: 0.17528437297012023\n",
            "Loss at epo 11: 0.17143849855274493\n",
            "Loss at epo 12: 0.16783472007956007\n",
            "Loss at epo 13: 0.16382886878197989\n",
            "Loss at epo 14: 0.16135633647054984\n",
            "Loss at epo 15: 0.15746435107336693\n",
            "Loss at epo 16: 0.15545464965120126\n",
            "Loss at epo 17: 0.15383958924473362\n",
            "Loss at epo 18: 0.1518017365943333\n",
            "Loss at epo 19: 0.149097337602331\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOQWiJQTO48s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d74604f-ad21-441c-d50d-3956537f449f"
      },
      "source": [
        "with torch.no_grad():\n",
        "  accurate = 0\n",
        "  for program, label in eval_data:\n",
        "   # print(program)\n",
        "   # print(label)\n",
        "   context_idx = get_programcontext(program)\n",
        "   model.zero_grad()\n",
        "   out = model(context_idx)\n",
        "   #print(f'{out}:{label}')\n",
        "   if(out[0]>0.5):\n",
        "     if(label == 0):\n",
        "       accurate =accurate+1\n",
        "   elif(out[1]>0.5):\n",
        "     if(label == 1):\n",
        "       accurate = accurate+1\n",
        "  print(f'Accuracy: {accurate/len(eval_data)}')   "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8652\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}